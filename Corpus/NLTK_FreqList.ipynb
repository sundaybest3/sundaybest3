{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundaybest3/sundaybest3/blob/main/Corpus/NLTK_FreqList.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üå± **Making a word list using {nltk} library**"
      ],
      "metadata": {
        "id": "hATtSCtDp9sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[sample text](https://read.gov/aesop/001.html)"
      ],
      "metadata": {
        "id": "jNATHoROqXnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input()"
      ],
      "metadata": {
        "id": "GbhLg5FLqisr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "\n",
        "text = \"This is an example sentence to test the removal of stop words and calculate frequency including 123 and '!'.\""
      ],
      "metadata": {
        "id": "S2blImVtnPVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Pre-processing"
      ],
      "metadata": {
        "id": "U2_1MqcqtW45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANc-4-qPnExP"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "# check nltk stopwords list at google.\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize #sentence_tokenize is also possible\n",
        "from nltk.probability import FreqDist # frequency distribution\n",
        "import re # regular expression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "XaHYqe5KnJ1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Prepare the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add more custom stop words\n",
        "additional_stop_words = [ ]\n",
        "stop_words.update(additional_stop_words)"
      ],
      "metadata": {
        "id": "3KBAb-7wnMoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Clean the text\n",
        "# Use regular expressions to remove punctuation and numbers\n",
        "clean_text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "clean_text = re.sub(r'\\d+', '', clean_text)  # Remove numbers"
      ],
      "metadata": {
        "id": "5IxYkeTbnwre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text"
      ],
      "metadata": {
        "id": "Vh5cQKN71Wv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "text > clean_text (after removing stop words, numbers, and punctuation)"
      ],
      "metadata": {
        "id": "uOIVUg7do6JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Tokenize the text and remove stop words\n",
        "words = word_tokenize(clean_text)\n",
        "filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n"
      ],
      "metadata": {
        "id": "QcWqBcOOnQyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "id": "cobXHTZs1xgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [2] Frequency distribution list"
      ],
      "metadata": {
        "id": "awefntyWtgT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create frequency distribution\n",
        "freq_dist = FreqDist(filtered_words)"
      ],
      "metadata": {
        "id": "kXNVpya6nR8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sorting by high frequency"
      ],
      "metadata": {
        "id": "36ku54MbtmOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7B: Convert frequency distribution to a sorted list of tuples (word, frequency)\n",
        "\n",
        "sorted_freq_list = sorted(freq_dist.items(), key=lambda x: x[1], reverse=True) # ÎßéÏùÄ Í≤ÉÏóêÏÑú ÏûëÏùÄ Í≤ÉÏúºÎ°ú\n",
        "\n",
        "# Display the sorted frequency list\n",
        "for word, frequency in sorted_freq_list:\n",
        "    print(f'{word}: {frequency}')\n"
      ],
      "metadata": {
        "id": "TekaiIuDq0Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] To dataframe and csv file"
      ],
      "metadata": {
        "id": "UKtMTCiVpOm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Convert frequency distribution to a DataFrame and a csv file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(sorted_freq_list, columns=['Word', 'Frequency'])"
      ],
      "metadata": {
        "id": "0E5GgSompFiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Save the DataFrame to a CSV file\n",
        "csv_file_path = '/content/word_frequencies.csv'\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "#df.to_csv(csv_file_path) # save the file with index (note that it starts from 0)\n",
        "\n",
        "print(f\"Frequency list saved to CSV file at: {csv_file_path}\")"
      ],
      "metadata": {
        "id": "ASQwEZq5plPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [4] Check the result"
      ],
      "metadata": {
        "id": "lSmuwCWgt4JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "UwtBlwASprO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# The end"
      ],
      "metadata": {
        "id": "EV5gw8NbtIuR"
      }
    }
  ]
}